{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Neural Network to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('datasets/mnist/train.csv')\n",
    "mnist_test = pd.read_csv('datasets/mnist/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60.000 images with 28 x 28 x 1 in train dataset\n",
    "# 10.000 images with 28 x 28 x 1 in test dataset\n",
    "\n",
    "mnist_train.shape, mnist_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = mnist_train[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
       "1    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[1 rows x 784 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rows_without_label_column = first_row.drop('label', axis=1)\n",
    "\n",
    "first_rows_without_label_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 784), numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = first_rows_without_label_column.values\n",
    "image.shape, type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.reshape(1, 28, 28)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is representation of the single image with the channel dimension first; height and width are the remaining two dimension. The squeeze function in a numpy array allows you to quickly eliminate those dimensions which have just single values. So image.squeeze will remove the unwanted one-dimensional access, so that we have an image which is just 28 x 28, and the first dimension has been squeezed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.squeeze()\n",
    "image.shape, type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training model using DNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropna drop all columns which has missing value\n",
    "\n",
    "mnist_train = mnist_train.dropna()\n",
    "mnist_test = mnist_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.shape, mnist_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_features = mnist_train.drop('label', axis=1)\n",
    "mnist_train_target = mnist_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images\n",
      "       1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
      "0        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "1        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "2        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "3        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "4        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
      "59995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "\n",
      "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0          0      0      0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "59995      0      0      0      0      0      0      0      0  \n",
      "59996      0      0      0      0      0      0      0      0  \n",
      "59997      0      0      0      0      0      0      0      0  \n",
      "59998      0      0      0      0      0      0      0      0  \n",
      "59999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[60000 rows x 784 columns]\n",
      "\n",
      "\n",
      "All labels\n",
      "0        5\n",
      "1        0\n",
      "2        4\n",
      "3        1\n",
      "4        9\n",
      "        ..\n",
      "59995    8\n",
      "59996    3\n",
      "59997    5\n",
      "59998    6\n",
      "59999    8\n",
      "Name: label, Length: 60000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('All images')\n",
    "print(mnist_train_features)\n",
    "\n",
    "print('\\n')\n",
    "print('All labels')\n",
    "print(mnist_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_features = mnist_test.drop('label', axis=1)\n",
    "mnist_test_target = mnist_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train max -  255\n",
      "train min -  0\n",
      "test max -  255\n",
      "test min -  0\n"
     ]
    }
   ],
   "source": [
    "print('train max - ', mnist_train.values.max())\n",
    "print('train min - ', mnist_train.values.min())\n",
    "print('test max - ', mnist_test.values.max())\n",
    "print('test min - ', mnist_test.values.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see that these are integer values representing intensity. It's been empirically shown that machine learning models such as neural network, train and perform **better** when they're dealing with **smaller numbers**, **smaller floating-point numbers**, as opposed to large values. Let's convert all of our data to float32 and divide all of our data by 255 so pixel intensity values are expressed **in the range 0-1**, and we'll do the exact same thing for the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.astype('float32')\n",
    "mnist_train = mnist_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = mnist_test.astype('float32')\n",
    "mnist_test = mnist_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train max -  1.0\n",
      "train min -  0.0\n",
      "test max -  1.0\n",
      "test min -  0.0\n"
     ]
    }
   ],
   "source": [
    "print('train max - ', mnist_train.values.max())\n",
    "print('train min - ', mnist_train.values.min())\n",
    "print('test max - ', mnist_test.values.max())\n",
    "print('test min - ', mnist_test.values.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(mnist_train_features.values, dtype=torch.float)\n",
    "x_test_tensor = torch.tensor(mnist_test_features.values, dtype=torch.float)\n",
    "\n",
    "y_train_tensor = torch.tensor(mnist_train_target.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(mnist_test_target.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape, y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60, 000 images, and each image has 784 pixels, and there are 60, 000 corresponding labels as well. When we feed in images to a deep neural network, we'll feed them in as one-dimensional vectors. Deep neural networks do not accept images in the original two-dimensional format with height and width. Let's take a look at our test data. Next there are 10, 000 test images that we'll use to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch neural network\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # Size of an image\n",
    "output_size = 10 # 10 categories: 0, 1, 2, 3, 4, 5 ,6 7, 8, 9\n",
    "\n",
    "hidden1_size = 16 # First hidden layer with 16 neurons\n",
    "hidden2_size = 32 # Second hidden layer with 32 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net inherit from nn.Module\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 3 layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size) # Input layer\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.fc3 = nn.Linear(hidden2_size, output_size) # Output layer\n",
    "\n",
    "    # Called in forward pass of neural network\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Applied sigmoid activation function to our first two layer\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        \n",
    "        # Output of the first layer pass to the second layer\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        # Output of the second layer pass to the third layer\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # Equivalent to log(softmax()) and used with the NLLLoss function. \n",
    "        # More stable numerically and has better performance\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = x_train_tensor.to(device)\n",
    "x_test_tensor = x_test_tensor.to(device)\n",
    "\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains optimizers for training models\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally efficient optimization algorithm with low memory requirements \n",
    "# works well with large datasets\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now run training for a total of 500 epochs, that is 500 passes through our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_of_epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(x_train_tensor)\n",
    "\n",
    "        loss = loss_function(Y_pred, y_train_tensor)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch - %d, loss - %0.2f ' %(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 10, loss - 2.26 \n",
      "Epoch - 20, loss - 2.21 \n",
      "Epoch - 30, loss - 2.17 \n",
      "Epoch - 40, loss - 2.14 \n",
      "Epoch - 50, loss - 2.10 \n",
      "Epoch - 60, loss - 2.06 \n",
      "Epoch - 70, loss - 2.02 \n",
      "Epoch - 80, loss - 1.97 \n",
      "Epoch - 90, loss - 1.92 \n",
      "Epoch - 100, loss - 1.86 \n",
      "Epoch - 110, loss - 1.81 \n",
      "Epoch - 120, loss - 1.75 \n",
      "Epoch - 130, loss - 1.70 \n",
      "Epoch - 140, loss - 1.64 \n",
      "Epoch - 150, loss - 1.59 \n",
      "Epoch - 160, loss - 1.54 \n",
      "Epoch - 170, loss - 1.49 \n",
      "Epoch - 180, loss - 1.44 \n",
      "Epoch - 190, loss - 1.40 \n",
      "Epoch - 200, loss - 1.35 \n",
      "Epoch - 210, loss - 1.31 \n",
      "Epoch - 220, loss - 1.27 \n",
      "Epoch - 230, loss - 1.23 \n",
      "Epoch - 240, loss - 1.19 \n",
      "Epoch - 250, loss - 1.15 \n",
      "Epoch - 260, loss - 1.12 \n",
      "Epoch - 270, loss - 1.08 \n",
      "Epoch - 280, loss - 1.05 \n",
      "Epoch - 290, loss - 1.02 \n",
      "Epoch - 300, loss - 0.99 \n",
      "Epoch - 310, loss - 0.96 \n",
      "Epoch - 320, loss - 0.93 \n",
      "Epoch - 330, loss - 0.90 \n",
      "Epoch - 340, loss - 0.88 \n",
      "Epoch - 350, loss - 0.85 \n",
      "Epoch - 360, loss - 0.83 \n",
      "Epoch - 370, loss - 0.81 \n",
      "Epoch - 380, loss - 0.79 \n",
      "Epoch - 390, loss - 0.77 \n",
      "Epoch - 400, loss - 0.75 \n",
      "Epoch - 410, loss - 0.73 \n",
      "Epoch - 420, loss - 0.72 \n",
      "Epoch - 430, loss - 0.70 \n",
      "Epoch - 440, loss - 0.68 \n",
      "Epoch - 450, loss - 0.67 \n",
      "Epoch - 460, loss - 0.65 \n",
      "Epoch - 470, loss - 0.64 \n",
      "Epoch - 480, loss - 0.63 \n",
      "Epoch - 490, loss - 0.62 \n",
      "Epoch - 500, loss - 0.61 \n"
     ]
    }
   ],
   "source": [
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to switch over our model to the eval mode. The eval mode ensures that layers and operations that should be applied only in training mode, such as dropout and regularization, will be turned off in eval or prediction mode. We don't have any such layers. We anyway switch the model over to the eval mode because that's the right thing to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use model for prediction\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a classifier model, the metrics used to evaluate the model is accuracy, precision, and recall, and we'll import these functions from the sklearn library. When we use a model for prediction, we turn off gradient calculations, we enclose all of our code within a torch.no_grad block. We'll initialize two variables that'll keep track of the total number of correct predictions and the total number of predictions. We then feed all of the 10, 000 images in our test tensor to our model, and store the output of the model in the outputs variable. In order to get the predictions of our model, we need to find the maximum probability score from our output. That will give us the predicted label for each input image in the test data. Our test tensor and the model parameters are all on the GPU. I now get the actual labels from our y_test_tensor in the numpy format, and I get the predicted labels from our model onto the CPU before I calculate the accuracy, precision, and recall scores. Accuracy, precision, and recall are calculated using the actual labels from the test data versus the predicted labels from our model. This classification model performs multi-class classification, that is the input image can belong to one of ten categories. To calculate precision and recall scores for multi-class calculation, you need an averaging method, and the weighted method basically averages these scores based on the number of samples of the different categories in your test data. And you can see from the results here that accuracy, precision, and recall scores are all around 85%. This simple, fully connected neural network worked well when we had a simple image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8529\n",
      "Precision:  0.85377086911286\n",
      "Recall:  0.8529\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    outputs = model(x_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    y_test = y_test_tensor.cpu().numpy()\n",
    "    predicted = predicted.cpu()\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(predicted, y_test))\n",
    "    print('Precision: ', precision_score(predicted, y_test, average='weighted'))\n",
    "    print('Recall: ', recall_score(predicted, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
